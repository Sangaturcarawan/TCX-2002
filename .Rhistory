set.seed(123)
complaint_times <- rgamma(100, shape = 2, scale = 5)
complaint_times
head(complaint_times)
mean(complaint_times)
sd(complaint_times)
plot(complaint_times)
barplot(complaint_times)
hist(complaint_times)
pie(complaint_times)
hist(complaint_times, main = "Complaint Resolution Times", xlab = "Time (hours)")
hist(complaint_times, breaks = 30, main = "Complaint Resolution Times", xlab = "Time (hours)")
plot(complaint_times)
barplot(complaint_times)
hist(complaint_times)
complaint_times
summary(complaint_times)
plot(complaint_times)
barplot(complaint_times)
hist(complaint_times)
plot(complaint_times)
barplot(complaint_times)
hist(complaint_times)
hist(complaint_times, main = "Complaint Resolution Times", xlab = "Time (hours)")
hist(complaint_times, breaks = 30, main = "Complaint Resolution Times", xlab = "Time (hours)")
mean_time <- mean(complaint)
mean_time <- mean(complaint_times)
sd_time <- sd(complaint_times)
cat("Mean resolution time:", round(mean_time, 2), "hours\n")
cat("Standard deviation:", round(sd_time, 2), "hours\n")
n <- length(complaint_times)
# 3. Compute a 95% confidence interval for average resolution time.
mean_time
sd_time
n
std_error <- sd_time/sqrt(n)
std_error
qnorm(0.975)
confidence_int_lower <- mean(complaint_times) - qnorm(0.975) * sd(complaint_times) / sqrt(length(complaint_times))
confidence_int_lower
qnorm(0.95)
margin_error <- qnorm()
qnorm(0.975)
qnorm(0.95)
margin_error <- qnorm(1 - alpha_sig_lvl/2)
z-value <- qnorm(1 - alpha_sig_lvl/2)
confidence_ints <- mean(complaint_times) + c(-1,1) * qnorm(0.975) * sd(complaint_times) / sqrt(length(complaint_times))
confidence_ints
# Set a seed for reproducibility
set.seed(123)
# Create a dummy dataset of 100 complaint resolution times (in hours)
# We use a distribution that is skewed to the right (more common in real data)
complaint_times <- rgamma(100, shape = 2, scale = 5)
# Display the first few entries of the dataset & simple visual
head(complaint_times)
plot(complaint_times)
barplot(complaint_times)
hist(complaint_times) # Best
pie(complaint_times)
# Visualize the distribution of the data
hist(complaint_times, main = "Complaint Resolution Times", xlab = "Time (hours)")
hist(complaint_times, breaks = 30, main = "Complaint Resolution Times", xlab = "Time (hours)")
### Calculate the mean (average) resolution time ###
mean_time <- mean(complaint_times)
# Calculate the standard deviation
sd_time <- sd(complaint_times)
# Print the results
cat("Mean resolution time:", round(mean_time, 2), "hours\n")
cat("Standard deviation:", round(sd_time, 2), "hours\n")
### Compute a 95% Confidence Interval ###
# Sample size (100)
n <- length(complaint_times)
# Z-score for a 95% confidence interval
z_score <- 1.96
# Calculate the standard error of the mean
standard_error <- sd_time / sqrt(n)
# Calculate the margin of error
margin_of_error <- z_score * standard_error
# Calculate the confidence interval bounds
lower_bound <- mean_time - margin_of_error
upper_bound <- mean_time + margin_of_error
# Print the confidence interval
cat("95% Confidence Interval of mean resolution time: [", round(lower_bound, 2), ", ", round(upper_bound, 2), "] hours\n")
confidence_ints <- mean(complaint_times) + c(-1,1) * qnorm(0.975) * sd(complaint_times) / sqrt(length(complaint_times))
confidence_ints
# Scenario: An e-commerce site tracks conversion rates. In 1,200 visitors:
#   • 84 made purchases • Sample conversion rate: p̂= 84/1,200 = 7%
# Lab Questions:
#   1. Check if conditions are met for normal approximation
x <- 84
n <- 1200
p_hat <- x/n
p_hat
# Scenario: An e-commerce site tracks conversion rates. In 1,200 visitors:
#   • 84 made purchases • Sample conversion rate: p̂= 84/1,200 = 7%
# Lab Questions:
#   1. Check if conditions are met for normal approximation
x <- 84
n <- 1200
p_hat <- x/n
p_hat
np <- n * p_hat
nq <- n * (1-p_hat)
normal_ok <- (np >= 10) && (nq >= 10)
normal_ok
std_err <- sqrt(p_hat * (1-p_hat) / n)
# 3. Build 95% confidence interval for true conversion rate
z_value <- qnorm(0.975)
# 2. Calculate standard error for the proportion
std_err <- sqrt(p_hat * (1-p_hat) / n)
# 3. Build 95% confidence interval for true conversion rate
z_value <- qnorm(0.975)
intervals <- p_hat + c(-1,1) * z_value * std_err
intervals
round(intervals,2)
intervals
p_hat
library(tidyverse)
library(dplyr)
library(lubridate)
library(moments)
library(car)
# 1. One-Sample t-test
# Scenario: A coffee chain claims that its average daily sales is $500, in the past month. You
# are asked to verify this.
# Dataset:
# A vector of 30 daily sales figures:
sales <- c(595, 447, 477, 423, 570, 547, 541, 490, 593, 557, 533, 482, 516, 590,
476, 499, 419, 509, 430, 479, 502, 511, 496, 471, 554, 596, 485, 534, 414, 443)
# 2. Paired Sample t-test
# Scenario: A 10-day marketing campaign was launched. You want to test whether customer
# online visits to the online shop increased during the campaign vs the 10 days before.
before <- c(125, 153, 148, 113, 139, 123, 106, 146, 119, 172)
mean_sales <- mean(sales)
mean_sales
source("~/TCX-2002/TCX_Tutorial_2.R")
?t.test
t.test(sales, mu=500)
length(sales)
df(sales)
before <- c(125, 153, 148, 113, 139, 123, 106, 146, 119, 172)
after <- c(140, 165, 154, 122, 148, 194, 164, 152, 200, 197)
before <- c(125, 153, 148, 113, 139, 123, 106, 146, 119, 172)
after <- c(140, 165, 154, 122, 148, 194, 164, 152, 200, 197)
?t.test
t.test(before, after, paired=TRUE, alternative="greater")
t.test(before, after, paired=TRUE)
t.test(before, after, paired=TRUE)
# Normality for each group
# Shapiro–Wilk per group => ensures t-test's normality assumption is reasonable.
shapiro.test(before)
shapiro.test(after)
shapiro.test(before)
shapiro.test(after)
t.test(before, after, paired=TRUE)
?aov()
branch <- factor(c(rep("North",4), rep("South",4), rep("Central",4)))
score <- c(3.2, 3.5, 3.7, 3.2, 4.0, 4.2, 3.9, 3.6, 3.7, 3.6, 3.4, 3.9)
branch
score
aov(score ~ branch)
aovmodel <- aov(score ~ branch)
aovmodel
summary(aovmodel)
boxplot(score ~ branch,
main = "Scores by Branch",
ylab = "Score",
boxplot(score ~ branch, main = "Scores by Branch", xlab = "Branch", ylab = "Score", col = c("lightblue", "lightgreen", "lightpink")
boxplot(score ~ branch, main = "Scores by Branch", xlab = "Branch", ylab = "Score", col = c("lightblue", "lightgreen", "lightpink")
boxplot(score ~ branch,
main = "Scores by Branch",
xlab = "Branch",
ylab = "Score",
col = c("lightblue", "lightgreen", "lightpink"))
points(tapply(score, branch, mean), col="red", pch=19)
diet <- factor(rep(c("A", "B", "C"), each = 5))
loss <- c(2.1, 2.5, 2.0, 2.9, 2.4, # Diet A
3.0, 3.2, 2.8, 3.5, 3.1, # Diet B
1.8, 2.0, 2.2, 1.9, 2.1) # Diet C
modelaov <- aov(loss ~ diet)
modelaov
summary(modelaov)
# Boxplot of weight loss by diet
boxplot(loss ~ diet,
main = "Weight Loss by Diet Plan",
xlab = "Diet Plan",
ylab = "Weight Loss (kg)",
col = c("lightblue", "lightgreen", "lightpink"))
# Add mean points in red
points(tapply(loss, diet, mean), col="red", pch=19)
before <- c(8, 6, 7, 9, 10, 5, 8, 7, 6, 9)
after <- c(5, 4, 5, 6, 8, 3, 6, 5, 4, 6)
t.test(before, after, paired=TRUE, alternative="greater")
